{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PB3qQCjCk9Qj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Activation, Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.layers import Dense, Dropout, Activation,Flatten\n",
        "from keras import metrics, regularizers\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn import metrics\n",
        "from keras.layers import Dense, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ddf = pd.read_csv(\"/content/yuz_veri_kumesi.csv\", sep=\";\")\n",
        "df = ddf[['Cumle','Sinif']]\n",
        "\n",
        "# The maximum number of words to be used. (most frequent)\n",
        "MAX_NB_WORDS = 5000\n",
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 50\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 100\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
        "tokenizer.fit_on_texts(df['Cumle'].values)\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df['Cumle'].values)\n",
        "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X.shape)\n",
        "\n",
        "Y = pd.get_dummies(df['Sinif']).values\n",
        "print('Shape of label tensor:', Y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWW1tCW3lYQY",
        "outputId": "6eae08ad-e31f-4d0c-8fe8-7acbc0ac2387"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20646 unique tokens.\n",
            "Shape of data tensor: (6109, 50)\n",
            "Shape of label tensor: (6109, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.7, random_state = 42)\n",
        "print(X_train.shape,Y_train.shape)\n",
        "print(X_test.shape,Y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeCbMqz5lYS9",
        "outputId": "cc90067f-4d89-4bf0-8fad-410f6ecd062f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1832, 50) (1832, 7)\n",
            "(4277, 50) (4277, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "batch_size = 256\n",
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(LSTM(256, activation='relu', dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "\n",
        "model.add(LSTM(128, activation='relu', dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "model.add(LSTM(128, activation='relu', dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
        "\n",
        "model.add(LSTM(16, activation='relu', dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "model.add(Dense(512, activation='LeakyReLU'))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['acc'])\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "\n",
        "accr= model.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.4f}\\n  Accuracy: {:0.4f}'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnaPl6pKlYU5",
        "outputId": "56f9b420-fd8d-42db-f79b-8ae62232f722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "7/7 [==============================] - 24s 1s/step - loss: 1.9152 - acc: 0.4624 - val_loss: 1.8472 - val_acc: 0.5380\n",
            "Epoch 2/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 8.2800 - acc: 0.5370 - val_loss: 1.4430 - val_acc: 0.5380\n",
            "Epoch 3/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5874 - acc: 0.5370 - val_loss: 1.6718 - val_acc: 0.5380\n",
            "Epoch 4/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.6448 - acc: 0.5370 - val_loss: 1.6187 - val_acc: 0.5380\n",
            "Epoch 5/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.5733 - acc: 0.5370 - val_loss: 1.5248 - val_acc: 0.5380\n",
            "Epoch 6/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.4591 - acc: 0.5370 - val_loss: 1.3710 - val_acc: 0.5380\n",
            "Epoch 7/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2703 - acc: 0.5370 - val_loss: 1.2608 - val_acc: 0.5380\n",
            "Epoch 8/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2297 - acc: 0.5370 - val_loss: 1.2456 - val_acc: 0.5380\n",
            "Epoch 9/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2184 - acc: 0.5370 - val_loss: 1.2389 - val_acc: 0.5380\n",
            "Epoch 10/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2060 - acc: 0.5370 - val_loss: 1.2330 - val_acc: 0.5380\n",
            "Epoch 11/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.1942 - acc: 0.5370 - val_loss: 1.2295 - val_acc: 0.5380\n",
            "Epoch 12/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.1848 - acc: 0.5370 - val_loss: 1.2137 - val_acc: 0.5380\n",
            "Epoch 13/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.1712 - acc: 0.5370 - val_loss: 1.1972 - val_acc: 0.5380\n",
            "Epoch 14/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.1299 - acc: 0.5370 - val_loss: 1.1572 - val_acc: 0.5380\n",
            "Epoch 15/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.0378 - acc: 0.5376 - val_loss: 1.1373 - val_acc: 0.5326\n",
            "Epoch 16/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.9284 - acc: 0.5492 - val_loss: 2615.7280 - val_acc: 0.4946\n",
            "Epoch 17/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.3034 - acc: 0.6311 - val_loss: 1.2992 - val_acc: 0.5870\n",
            "Epoch 18/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.1812 - acc: 0.6286 - val_loss: 1.2097 - val_acc: 0.5978\n",
            "Epoch 19/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.0730 - acc: 0.6201 - val_loss: 16.9146 - val_acc: 0.5815\n",
            "Epoch 20/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.9003 - acc: 0.6195 - val_loss: 0.8940 - val_acc: 0.5978\n",
            "Epoch 21/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.7410 - acc: 0.6675 - val_loss: 0.9280 - val_acc: 0.6250\n",
            "Epoch 22/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.6347 - acc: 0.7518 - val_loss: 1.3832 - val_acc: 0.7011\n",
            "Epoch 23/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.9997 - acc: 0.7530 - val_loss: 3.9329 - val_acc: 0.6250\n",
            "Epoch 24/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.2183 - acc: 0.7470 - val_loss: 7.1745 - val_acc: 0.6576\n",
            "Epoch 25/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 1.7000 - acc: 0.7676 - val_loss: 45.5029 - val_acc: 0.6141\n",
            "Epoch 26/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 224.8981 - acc: 0.6110 - val_loss: 353.4731 - val_acc: 0.3370\n",
            "Epoch 27/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 147.1502 - acc: 0.2002 - val_loss: 41.0814 - val_acc: 0.1522\n",
            "Epoch 28/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 156.8666 - acc: 0.1596 - val_loss: 5.9192 - val_acc: 0.1304\n",
            "Epoch 29/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 4.2663 - acc: 0.2427 - val_loss: 1.8155 - val_acc: 0.3696\n",
            "Epoch 30/30\n",
            "7/7 [==============================] - 8s 1s/step - loss: 2.0790 - acc: 0.4818 - val_loss: 1.1934 - val_acc: 0.5598\n",
            "134/134 [==============================] - 9s 65ms/step - loss: 1.2116 - acc: 0.5600\n",
            "Test set\n",
            "  Loss: 1.2116\n",
            "  Accuracy: 0.5600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = [row[0] for row in Y_test]\n",
        "from sklearn import metrics\n",
        "y_pred=model.predict(X_test)\n",
        "dene = np.argmax(y_pred, axis=1)\n",
        "a = np.argmax(Y_test, axis=1)\n",
        "print(\"F1: \",f1_score(a[:],dene[:],average='weighted'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpzWrhgYlYYU",
        "outputId": "33f3093b-e462-4368-fee4-acfa936ab9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1:  0.4868011578207406\n"
          ]
        }
      ]
    }
  ]
}