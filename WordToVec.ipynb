{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WordToVec.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0YQqQCTxh7V",
        "outputId": "f2bcc9d1-9ed2-448b-adaf-72f091991c52"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "HwWAT6uOmiYc"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import warnings\n",
        "import re\n",
        "warnings.filterwarnings(action = 'ignore')\n",
        " \n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = open(\"/content/ALL.txt\")\n",
        "s = sample.read()\n",
        " \n",
        "# Replaces escape character with space\n",
        "f = s.replace(\"\\n\", \" \")"
      ],
      "metadata": {
        "id": "q9-7Pw0dwFvc"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        " \n",
        "# iterate through each sentence in the file\n",
        "for i in sent_tokenize(f):\n",
        "    temp = []\n",
        "     \n",
        "    # tokenize the sentence into words\n",
        "    for j in word_tokenize(i):\n",
        "        temp.append(j.lower())\n",
        " \n",
        "    data.append(temp)"
      ],
      "metadata": {
        "id": "1lJrbYzhzcMo"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create CBOW model\n",
        "model1 = gensim.models.Word2Vec(data, min_count = 1, window = 5)\n",
        "word1=\"yüzyıl\"\n",
        "word2=\"yüzlerce\"\n",
        "word3=\"yüzünden\"\n",
        "# Print results\n",
        "print(\"Cosine similarity between \"+word1+\n",
        "               \" and \"+word2+\" - CBOW : \",\n",
        "    model1.wv.similarity(word1, word2))\n",
        "     \n",
        "print(\"Cosine similarity between \"+word1+\n",
        "               \" and \"+word3+\" - CBOW : \",\n",
        "    model1.wv.similarity(word1, word3))\n",
        " \n",
        "# Create Skip Gram model\n",
        "model2 = gensim.models.Word2Vec(data, min_count = 1, window = 5, sg = 1)\n",
        "\n",
        "# Print results\n",
        "print(\"Cosine similarity between \",word1+\n",
        "               \" and \",word2+\" - Skip Grow : \",\n",
        "    model2.wv.similarity(word1, word2))\n",
        "     \n",
        "print(\"Cosine similarity between \"+word1+\n",
        "               \" and \"+word3+\" - Skip Grow : \",\n",
        "    model2.wv.similarity(word1, word3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQsGdycZ3lcb",
        "outputId": "9b5879e0-635f-45b1-ea85-c273ed94a753"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between yüzyıl and yüzlerce - CBOW :  0.7474375\n",
            "Cosine similarity between yüzyıl and yüzünden - CBOW :  0.54639834\n",
            "Cosine similarity between  yüzyıl and  yüzlerce - Skip Grow :  0.5082283\n",
            "Cosine similarity between yüzyıl and yüzünden - Skip Grow :  0.28651816\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"CBOW_Model\")\n",
        "model2.save(\"SkipGram_Model\")"
      ],
      "metadata": {
        "id": "QukP8Qwk5zge"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelCBOW=Word2Vec.load(\"CBOW.model\")\n",
        "modelSkipGram=Word2Vec.load(\"SkipGram.model\")"
      ],
      "metadata": {
        "id": "nf3YTPEH6exP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word4=\"binici\"\n",
        "word5=\"binlerce\"\n",
        "word6=\"binek\"\n",
        "# Print results\n",
        "print(\"Cosine similarity between \"+word4+\n",
        "               \" and \"+word5+\" - CBOW : \",\n",
        "    model1.wv.similarity(word4, word5))\n",
        "     \n",
        "print(\"Cosine similarity between \"+word4+\n",
        "               \" and \"+word6+\" - CBOW : \",\n",
        "    model1.wv.similarity(word4, word6))\n",
        "\n",
        "# Print results\n",
        "print(\"Cosine similarity between \",word4+\n",
        "               \" and \",word5+\" - Skip Grow : \",\n",
        "    model2.wv.similarity(word4, word5))\n",
        "     \n",
        "print(\"Cosine similarity between \"+word4+\n",
        "               \" and \"+word6+\" - Skip Grow : \",\n",
        "    model2.wv.similarity(word4, word6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryYzER2NoxBi",
        "outputId": "e9135322-27ae-41f0-b1d2-22b6c7c1c030"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity between binici and binlerce - CBOW :  0.4987396\n",
            "Cosine similarity between binici and binek - CBOW :  0.8441894\n",
            "Cosine similarity between  binici and  binlerce - Skip Grow :  0.54029185\n",
            "Cosine similarity between binici and binek - Skip Grow :  0.8161958\n"
          ]
        }
      ]
    }
  ]
}
